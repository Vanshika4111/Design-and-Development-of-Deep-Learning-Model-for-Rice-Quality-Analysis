{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7494401,"sourceType":"datasetVersion","datasetId":4363798},{"sourceId":8020410,"sourceType":"datasetVersion","datasetId":4726009}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" #  **Design and Developement of Deep learning model for Rice Quality Analysis**","metadata":{"execution":{"iopub.status.busy":"2024-04-03T15:49:37.290356Z","iopub.execute_input":"2024-04-03T15:49:37.290765Z","iopub.status.idle":"2024-04-03T16:36:47.966213Z","shell.execute_reply.started":"2024-04-03T15:49:37.290734Z","shell.execute_reply":"2024-04-03T16:36:47.964568Z"}}},{"cell_type":"markdown","source":"### **Importing necessary libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom skimage import measure\nimport cv2\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.utils import class_weight\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:48:36.41218Z","iopub.execute_input":"2024-05-17T10:48:36.412617Z","iopub.status.idle":"2024-05-17T10:48:52.964393Z","shell.execute_reply.started":"2024-05-17T10:48:36.412584Z","shell.execute_reply":"2024-05-17T10:48:52.963128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Analysing single rice image and trying to resize it**","metadata":{}},{"cell_type":"code","source":"img = cv2.imread('/kaggle/input/rice-image1600/rice_image16000/Basmati/basmati007.jpg')\nplt.imshow(img)\nplt.title(\"Original Image\")\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:53:37.884103Z","iopub.execute_input":"2024-05-17T10:53:37.8845Z","iopub.status.idle":"2024-05-17T10:53:40.026049Z","shell.execute_reply.started":"2024-05-17T10:53:37.884469Z","shell.execute_reply":"2024-05-17T10:53:40.024785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:53:47.055159Z","iopub.execute_input":"2024-05-17T10:53:47.055523Z","iopub.status.idle":"2024-05-17T10:53:47.062493Z","shell.execute_reply.started":"2024-05-17T10:53:47.055496Z","shell.execute_reply":"2024-05-17T10:53:47.060893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_image = cv2.resize(img, (700, 700))\n\nplt.imshow(resized_image)\nplt.title(\"resized image\")\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:53:48.381282Z","iopub.execute_input":"2024-05-17T10:53:48.381969Z","iopub.status.idle":"2024-05-17T10:53:48.702442Z","shell.execute_reply.started":"2024-05-17T10:53:48.381926Z","shell.execute_reply":"2024-05-17T10:53:48.700787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_image.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:57:48.021208Z","iopub.execute_input":"2024-05-17T10:57:48.021615Z","iopub.status.idle":"2024-05-17T10:57:48.030592Z","shell.execute_reply.started":"2024-05-17T10:57:48.021586Z","shell.execute_reply":"2024-05-17T10:57:48.028791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Implementing Function for rice feature Extraction**","metadata":{}},{"cell_type":"code","source":"def calculate_features(image_path):\n    \n    #loading images\n    image0 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    \n    #resizing images\n    image = cv2.resize(image0, (1000, 1000))\n    \n    #Segmentation of image\n    _, thresh = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n    \n    kernel = np.ones((5, 5), np.uint8)\n    morph_image = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n    contours, _ = cv2.findContours(morph_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    #Extracting the ROI\n    largest_contour = max(contours, key=cv2.contourArea)\n\n    #Calculating the area and perimeter from the extracted largest contour\n    area = cv2.contourArea(largest_contour)\n    perimeter = cv2.arcLength(largest_contour, True)\n\n    #This is for checking the largest_contour is >5 or not, because in case of <5 it will not be able to fit in any type of ellipse\n    if len(largest_contour) >= 5:\n        \n        #Trying to find the best fit ellipse\n        ellipse = cv2.fitEllipse(largest_contour)\n        \n        #Extracting the major and minor axis length from best fitted ellipse\n        minor_axis, major_axis = ellipse[1]\n        \n        #Calculating the aspect ratio\n        aspect_ratio = major_axis / minor_axis\n    else:\n        \n        #If largest_contour is <5 then major, minor and aspect ratio will be not a number(nan)\n        major_axis = minor_axis = aspect_ratio = np.nan\n\n    #Calculating the eccentricity of the ellipse\n    if minor_axis < major_axis:\n        eccentricity = np.sqrt(1 - (minor_axis / major_axis) ** 2)\n    else:\n        eccentricity = np.nan\n\n    #Calculating the other morphological features of rice\n    convex_hull = cv2.convexHull(largest_contour)\n    convex_area = cv2.contourArea(convex_hull)\n\n    equiv_diameter = np.sqrt(4 * area / np.pi)\n\n    x, y, w, h = cv2.boundingRect(largest_contour)\n    bounding_box_area = w * h\n\n    extent = area / bounding_box_area\n\n    solidity = area / convex_area\n\n    roundness = (4 * area) / (np.pi * major_axis ** 2)\n\n    compactness = (perimeter ** 2) / (4 * np.pi * area)\n\n    #Defining four different shape factors\n    shape_factor_1 = major_axis / area\n    shape_factor_2 = minor_axis / area\n    shape_factor_3 = area / ((major_axis / 2) * np.pi)\n    shape_factor_4 = area / ((major_axis / 2) * (minor_axis / 2) * np.pi)\n\n    #Create a dictionary with feature names and values\n    path1 = os.path.dirname(image_path)\n    features_dict = {\n        \"RiceName\": os.path.basename(path1),\n        \"Area\": area,\n        \"Perimeter\": perimeter,\n        \"MajorAxisLength\": major_axis,\n        \"MinorAxisLength\": minor_axis,\n        \"AspectRatio\": aspect_ratio,\n        \"Eccentricity\": eccentricity,\n        \"ConvexArea\": convex_area,\n        \"EquivalentDiameter\": equiv_diameter,\n        \"Extent\": extent,\n        \"Solidity\": solidity,\n        \"Roundness\": roundness,\n        \"Compactness\": compactness,\n        \"ShapeFactor1\": shape_factor_1,\n        \"ShapeFactor2\": shape_factor_2,\n        \"ShapeFactor3\": shape_factor_3,\n        \"ShapeFactor4\": shape_factor_4,\n    }\n\n    return features_dict","metadata":{"execution":{"iopub.status.busy":"2024-04-03T15:49:37.290356Z","iopub.execute_input":"2024-04-03T15:49:37.290765Z","iopub.status.idle":"2024-04-03T16:36:47.966213Z","shell.execute_reply.started":"2024-04-03T15:49:37.290734Z","shell.execute_reply":"2024-04-03T16:36:47.964568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Create an empty DataFrame to store the features**","metadata":{}},{"cell_type":"code","source":"features_df = pd.DataFrame(columns=[\"RiceName\", \"Area\", \"Perimeter\", \"MajorAxisLength\",\n                                     \"MinorAxisLength\", \"AspectRatio\", \"Eccentricity\",\n                                     \"ConvexArea\", \"EquivalentDiameter\", \"Extent\",\n                                     \"Solidity\", \"Roundness\", \"Compactness\",\n                                     \"ShapeFactor1\", \"ShapeFactor2\", \"ShapeFactor3\",\n                                     \"ShapeFactor4\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-03T15:49:37.290356Z","iopub.execute_input":"2024-04-03T15:49:37.290765Z","iopub.status.idle":"2024-04-03T16:36:47.966213Z","shell.execute_reply.started":"2024-04-03T15:49:37.290734Z","shell.execute_reply":"2024-04-03T16:36:47.964568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Iterate through the images and calculate features**","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/rice-image1600'):\n    for filename in filenames:\n        image_path = os.path.join(dirname, filename)\n        features_dict = calculate_features(image_path)\n        features_row = pd.DataFrame([features_dict])\n        \n        features_df = pd.concat([features_df, features_row], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T15:49:37.290356Z","iopub.execute_input":"2024-04-03T15:49:37.290765Z","iopub.status.idle":"2024-04-03T16:36:47.966213Z","shell.execute_reply.started":"2024-04-03T15:49:37.290734Z","shell.execute_reply":"2024-04-03T16:36:47.964568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Save the DataFrame to a CSV file**","metadata":{}},{"cell_type":"code","source":"features_df.to_csv('rice_features.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T15:49:37.290356Z","iopub.execute_input":"2024-04-03T15:49:37.290765Z","iopub.status.idle":"2024-04-03T16:36:47.966213Z","shell.execute_reply.started":"2024-04-03T15:49:37.290734Z","shell.execute_reply":"2024-04-03T16:36:47.964568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Loading the dataset**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/rice-features/rice_features (2).csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:04:35.266818Z","iopub.execute_input":"2024-04-03T17:04:35.26723Z","iopub.status.idle":"2024-04-03T17:04:35.494037Z","shell.execute_reply.started":"2024-04-03T17:04:35.267198Z","shell.execute_reply":"2024-04-03T17:04:35.49276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:04:38.945539Z","iopub.execute_input":"2024-04-03T17:04:38.946615Z","iopub.status.idle":"2024-04-03T17:04:38.970772Z","shell.execute_reply.started":"2024-04-03T17:04:38.946576Z","shell.execute_reply":"2024-04-03T17:04:38.969615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Splitting dataset int X and Y**","metadata":{}},{"cell_type":"code","source":"X = data.drop('RiceName', axis=1)\ny = data['RiceName']","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:27:35.720662Z","iopub.execute_input":"2024-04-03T17:27:35.721659Z","iopub.status.idle":"2024-04-03T17:27:35.828872Z","shell.execute_reply.started":"2024-04-03T17:27:35.721621Z","shell.execute_reply":"2024-04-03T17:27:35.827674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Initializing some empty list**","metadata":{}},{"cell_type":"code","source":"f1_scores = []\nrecalls = []\nprecisions = []","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:27:35.720662Z","iopub.execute_input":"2024-04-03T17:27:35.721659Z","iopub.status.idle":"2024-04-03T17:27:35.828872Z","shell.execute_reply.started":"2024-04-03T17:27:35.721621Z","shell.execute_reply":"2024-04-03T17:27:35.827674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Encoding Categorical Labels and Standardizing Features in Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:27:35.720662Z","iopub.execute_input":"2024-04-03T17:27:35.721659Z","iopub.status.idle":"2024-04-03T17:27:35.828872Z","shell.execute_reply.started":"2024-04-03T17:27:35.721621Z","shell.execute_reply":"2024-04-03T17:27:35.827674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Building a Deep Neural Network with Dropout for Multiclass Classification**","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(128, activation='relu', input_dim=X_scaled.shape[1]))\nmodel.add(Dropout(0.5))  \n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\n\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(len(label_encoder.classes_), activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:27:35.720662Z","iopub.execute_input":"2024-04-03T17:27:35.721659Z","iopub.status.idle":"2024-04-03T17:27:35.828872Z","shell.execute_reply.started":"2024-04-03T17:27:35.721621Z","shell.execute_reply":"2024-04-03T17:27:35.827674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Computing Class Weights for Handling Imbalanced Data in Classification**","metadata":{}},{"cell_type":"code","source":"class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)\nclass_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:27:35.720662Z","iopub.execute_input":"2024-04-03T17:27:35.721659Z","iopub.status.idle":"2024-04-03T17:27:35.828872Z","shell.execute_reply.started":"2024-04-03T17:27:35.721621Z","shell.execute_reply":"2024-04-03T17:27:35.827674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Compiling a Neural Network Model for Multiclass Classification**\n","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:27:35.720662Z","iopub.execute_input":"2024-04-03T17:27:35.721659Z","iopub.status.idle":"2024-04-03T17:27:35.828872Z","shell.execute_reply.started":"2024-04-03T17:27:35.721621Z","shell.execute_reply":"2024-04-03T17:27:35.827674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Stratified K-Fold Cross-Validation for Model Evaluation**","metadata":{}},{"cell_type":"code","source":"num_folds = 6\nkf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n\nfold_accuracies = []     ","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:27:35.720662Z","iopub.execute_input":"2024-04-03T17:27:35.721659Z","iopub.status.idle":"2024-04-03T17:27:35.828872Z","shell.execute_reply.started":"2024-04-03T17:27:35.721621Z","shell.execute_reply":"2024-04-03T17:27:35.827674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Training Neural Network with Stratified K-Fold Cross-Validation**","metadata":{}},{"cell_type":"code","source":"for i, (train_index, val_index) in enumerate(kf.split(X_scaled, y_encoded)):\n    X_train_fold, X_val_fold = X_scaled[train_index], X_scaled[val_index]\n    y_train_fold, y_val_fold = y_encoded[train_index], y_encoded[val_index]\n\n    \n    model.fit(X_train_fold, y_train_fold, epochs=120, batch_size=128, class_weight=class_weight_dict, verbose=0)\n\n    \n    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n    fold_accuracies.append(val_accuracy)\n    print(f'Fold {i + 1} - Validation Accuracy: {val_accuracy * 100:.3f}%')","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:36:40.702631Z","iopub.execute_input":"2024-04-03T17:36:40.703111Z","iopub.status.idle":"2024-04-03T17:43:18.090186Z","shell.execute_reply.started":"2024-04-03T17:36:40.703078Z","shell.execute_reply":"2024-04-03T17:43:18.089071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Plotting Cross-Validation Accuracy of Neural Network Model**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.plot(range(1, num_folds + 1), [acc * 100 for acc in fold_accuracies], marker='o', linestyle='-')\nplt.xlabel('Fold')\nplt.ylabel('Accuracy (%)')\nplt.title('Accuracy of Each Fold')\nplt.grid(True)\nplt.xticks(range(1, num_folds + 1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-03T17:36:40.702631Z","iopub.execute_input":"2024-04-03T17:36:40.703111Z","iopub.status.idle":"2024-04-03T17:43:18.090186Z","shell.execute_reply.started":"2024-04-03T17:36:40.703078Z","shell.execute_reply":"2024-04-03T17:43:18.089071Z"},"trusted":true},"execution_count":null,"outputs":[]}]}